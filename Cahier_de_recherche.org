#+title: Cahier De Recherche
#+author: Djoser SIMEU

* mercredi 31 janvier 2024
** Prise en mains du repertoire gitHub
+ Fork du repertoire https://github.com/fredgrub/scheduling-simulator
+ Prise main de Docker
*** DONE :: Mettre à jour la version de python 3.9.12  -> 3.9.2
*** DONE :: Mieux comprendre l'utilisation de conteneurs docker
** Erreurs rencontrée :
+ You may still be able to access the file from the browser:https://drive.google.com/uc?id=1MkSKglrQeI8rEO9hbr-7kYEvSHhrpFKG but Gdown can't. Please check connections and permissions.
  + commande : sudo docker run --rm -v "$(pwd)":/workspaces/scheduling-simulator/ build-simgrid bash -c "python /workspaces/scheduling-simulator/initialize.py"
+ après l'éxécution de la commande : nohup python src/simulator/simulator.py & , le dossier data censé contenir les données de la simulation est vide.
  + donc la commande python /src/regressor/regressor.py échoue.
**** DONE :: regler l'erreur et comprendre la synthax de docker run



* vendredi 2 février
** Code modification
+ line 388 : src/simulator/trial_simulator.c -> commentary (todo[i]->name problem)
+ line 677 : src/tester/sched-simulator-runtime.c ->commentary (todo[i]->name problem)
+ line 624 : src/tester/sched-simulator-backfilling.c -> commentary (todo[i]->name problem)
*** DONE :: Understand why the todo[i]->name problem occur
** Files understanding
*** simulator.py
+ S = initial state of the HPC
+ Q = sets of jobs to be schedule into the HPC
+ SIMULATION_PARAMETERS :
  + number_of_tuples : number of binome S-Q
  + number_of_trials : number of time we schedule the jobs in Q
  + size_of_S : number of jobs in S
  + size_of_Q : number of jobs in Q
**** Simulator attributes
+ _jobs_S : the initial state of the simulated HPC before scheduling
+ _jobs_Q : the set of jobs to be schedule
***** DONE :: Verifier les autres attributs avec Danilo si possible
**** Simulator constructor
+ workload : workload model used to define the simulator
***** DONE :: Understand what does mean the arguments deployment, cluster and fixed_seed
**** Simulator Methods
***** get_workload_info(self)
initialize the number of jobs and processors by reading the workload given to the constructor
****** DONE :: What does mean model_jobs?
***** store_tuple(self, index)
store in _jobs_S and _jobs_Q jobs stored in model_jobs as it said in the paper with M, to apply this we used get_random_index() to define the begining of the set M.
+ Remark : _jobs_S and _jobs_Q -> ["p"]["q"]["r"]
+ Remark : nodes = processors
***** create_permutation (self, index, shuffled_Q)
As it's explain on the paper, we compute |Q| permutation of the set Q to construct multple branch of simulation.
****** DONE :: What does mean a branch of simulation?
***** schedule_trials(self)
Create a a new permutation for each trial
***** compute_AVGbsld(self,index)
Apply the computation of the score(j) based on the equation 3 of the paper
****** DONE :: more Understand the function
***** simulate(self)
call all the functions described previously to compute the simulation.
*** regressor.py
**** Regressor Attributes
+ functions : list of functions used for the multiple linear regression
+ data_set : dataset on which we compute the regression
**** Regressor Methods
***** _compute_weights(self)
compute the weights for the regression by computing 1/(p*q) for all the enteries of the dataset
***** _fit_function(self,function)
Fit the function given as parameter to the dataset by using scipy.optimize.curve_fit
****** TODO :: Understand what does curve_fit
***** _predict_y(self, function, optimal_parameters)
Applying the function given as parameter to the dataset and return the result in an array
***** _compute_mae(self, predicted_y)
compute the mean absolute error of the prediction with the attribute score of the dataset
***** regression(self, output_file, include_covariance=False)
apply the regression with all the functions contain by the object Regressor and write the result into a file
* mercredi 7 février
** File understanding
*** tester.py
**** workload_experiments(workloads, policies, sim_type)
***** Parameters
+ parameter workloads : an array of string which represent in which represent the workloads used to based our simulation
  + possible values :  ["CTC-SP2", "SDSC-BLUE", "LUBLIN 256"]
+ parameter policies : array of string which represent the policies used to schedule the jobs in Q in our experiments
  + possible values : ["FCFS", "WFP3", "UNICEF", "SPT", "SAF", "F2", "LIN", "QDR", "CUB", "QUA", "QUI", "SEX"]
+ parameter sim_type : an array of string which represent the type of simulator we want to use in our simulation
  + possible values : ["ACTUAL", "ESTIMATED"]
****** DONE :: knowing the role of each workload and the particularity of each simulation type
***** Function
+ incomprehension line 98-99 tester.py
+ 1 : strat by collecting informations about the workloads and the type of simulator used
+ 2 : defining a dataframe slowdown where to store all slowdowns from all experiments
+ 3.1 : Defining S and Q from the choosen workload as it's done in simulator.py
+ 3.2 : In the case where the type of simulator used is not "ACTUAL" we must additionally used the attribute ~p which represent the estimated job's processing time
+ 4 : Compute the scheduling experiment of Q for each policy in the parameter policies by the using of the method subprocess.run
+ 5 : write all the slowdowns computed during the experiment in a csv file
** Problem
*** DONE :: Simulation
When I want to launch the simulation by the command python tester.py the simulation didn't occurs and reapeat the same line  : [1295866.000000] [ker_engine/INFO] 2836 actors are still running, waiting for something.
+ Jean Francois said to me :
  + the simulation must start at 0 but in our case the simulation start at 1295866 so it's strange, the cause can be an error in  the end of the simulation. May be the problem can occurs durring the cloture of the simulation.
+ head of err.log :
#+begin_example
[0.000000] [surf_parse/INFO] You're using a v4.0 XML file (/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/data/platforms/plat_day.xml) while the current standard is v4.1 That's fine, the new version is backward compatible.

Use simgrid_update_xml to update your file automatically to get rid of this warning. This program is installed automatically with SimGrid, or available in the tools/ directory of the source archive.
[0.000000] [surf_parse/INFO] You're using a v4.0 XML file (/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/data/applications/deployment_ctcsp2.xml) while the current standard is v4.1 That's fine, the new version is backward compatible.

Use simgrid_update_xml to update your file automatically to get rid of this warning. This program is installed automatically with SimGrid, or available in the tools/ directory of the source archive.
[1295866.000000] ./src/kernel/EngineImpl.cpp:851: [ker_engine/CRITICAL] Oops! Deadlock or code not perfectly clean.
[1295866.000000] [ker_engine/INFO] 2836 actors are still running, waiting for something.
[1295866.000000] [ker_engine/INFO] Legend of the following listing: "Actor <pid> (<name>@<host>): <status>"
[1295866.000000] [ker_engine/INFO] Actor 1 (master@node-0) simcall Simcall::RUN_BLOCKING
#+end_example
+ nothing in out.log

**** part of the problem solved
un-commentation of the line commented 02/02/2024 but replacing todo[i]->name by todo[i]
+ out.log :
Performing scheduling performance test for the workload trace CTC-SP2.
Configuration: ACTUAL
Performing scheduling experiment 1. Number of tasks=2835
+ head err.log :
#+begin_example
[0.000000] [surf_parse/INFO] You're using a v4.0 XML file (/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/data/platforms/plat_day.xml) while the current standard is v4.1 That's fine, the new version is backward compatible.

Use simgrid_update_xml to update your file automatically to get rid of this warning. This program is installed automatically with SimGrid, or available in the tools/ directory of the source archive.
[0.000000] [surf_parse/INFO] You're using a v4.0 XML file (/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/data/applications/deployment_ctcsp2.xml) while the current standard is v4.1 That's fine, the new version is backward compatible.

Use simgrid_update_xml to update your file automatically to get rid of this warning. This program is installed automatically with SimGrid, or available in the tools/ directory of the source archive.
[0.000000] [surf_parse/INFO] You're using a v4.0 XML file (/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/data/platforms/plat_day.xml) while the current standard is v4.1 That's fine, the new version is backward compatible.

Use simgrid_update_xml to update your file automatically to get rid of this warning. This program is installed automatically with SimGrid, or available in the tools/ directory of the source archive.
[0.000000] [surf_parse/INFO] You're using a v4.0 XML file (/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/data/applications/deployment_ctcsp2.xml) while the current standard is v4.1 That's fine, the new version is backward compatible.
#+end_example
**** DONE :: Use nix (ask Dorian)
**** DONE :: Find the computation of VIF
+ In the method _fit_function(self,function) regressor.py line 77 by the call :
    scipy.optimize.curve_fit(
            function,
            (self.data_set["p"], self.data_set["q"], self.data_set["r"]),
            self.data_set["score"],
            sigma=self._compute_weights(),
            absolute_sigma=True,
        )
***** DONE :: reading curve_fit documentation : https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html
* vendredi 9 février
** Meeting with Danilo
*** Sucessing to run the simulation
Danilo send to me the file simgrid.nix which allow me to configure my nix-env withe the right version of simgrid by the command
#+begin_example
nix-shell simgrid.nix
#+end_example
Now I don't need to run initialize.py, i only need to call make in the directories src/tester and src/simulator
*** Genetique algorithm
To increase the precision and the speed of the computation of the targets given to the regressor for his learning, Danilo have implement a genetic algorithm which compute the best permutation of the set of jobs Q, the metric used to compare the permutation during the genetic algo is the AVGBoundedSlowdown.
**** DONE :: read the paper on the genetic algorithm (https://webmail.etu.univ-grenoble-alpes.fr/service/home/~/?auth=co&loc=fr&id=29065&part=2)
+ GA approche to solve RCPSP
**** DONE :: fork the branch https://github.com/fredgrub/scheduling-simulator/tree/dcsantos/genetic_algorithm_dataset_creation into my repositoty
**** DONE :: Implement the method save_score_distribution
***** DONE :: Compute the score of each jobs in the permutation find at the end of genetic algo by the method (rankof the jobs)/(number total of jobs in Q)
***** DONE :: Write the score associate to each jobs on the trainnig data file
**** DONE :: Find a way to define a stop criterion for the number of iteration of the genetic algorithm
* mercredi 14 février
** Preparation magisterial presentation
*** DONE :: The online job scheduling problem can be defined as an NP complete problem?
*** DONE :: Which option is better between talk more about simgrid or talk more about our implementation of the scheduling simulator?
*** DONE :: In the multiple linear regression model the family of functions represent in our case the set of function Lin, Qdr, Cub, Qua ...? And at the end we choose the one which have the best performance?
*** DONE :: Do we loose in explainabilty by using polynomiale features?
*** DONE :: In our simulation how many cores do we have?
*** DONE :: Do we use the same data in trainnig of the models and in the tester.c implementation?
*** DONE :: Data used come from real HPC plateform trace?
*** DONE :: How to define the average bounded slowdown with simple terms ?
* Vendredi 16 février
** Advecement on the Gen algo implementation
*** DONE :: Concatenate the dataset genrerated by the algo to construct our train dataset
+ Adding in simulator the attribute : _global_training_data_path = SIMULATION_DIR / "training-data"/ "global_training_data.csv"
+ Adding in simulator the attribute : self.global_data=open(self._global_training_data_path,"w+")
+ Adding in regressor the global variable : TRAINING_DIR = pathlib.Path(__file__).parent.parent / "simulator" / "training-data"
  + using it : SCORE_DISTRIBUTION = TRAINING_DIR / "global_training_data.csv"
*** DONE :: Define a way to stop the learning of the gen algo
** DONE ::posible utilisation d'une recherche profonde -> Gen algo
** DONE ::latin hypercube for the initialization of the population
** DONE ::Grid Search algo hyper parameter = nb gen , initiaalisation de la population
** DONE ::Jeu experimentale python simulator.py -random/-lhs
| tuple | random |  lhs |              |
|     1 |    512 |  450 |              |
|     2 |     30 |   25 |              |
|    .. |    ... |...   |              |
|    10 |    250 | 2520 | nb_gen = 500 |
metric = Average bounded slowdown
*** DONE :: find a way to use latin hypercube (agrparse)
#+begin_example
for j in range(0, self.population_size):
            self._parents_indices[j] = np.arange(self.size_of_Q)
            shuffle(self._parents_indices[j])
#+end_example
to replace if we use the option -lhs:
#+begin_example
def initialize_population_indexes(self):
        #if self._current_generation == 0:
        self._parents_indices = np.empty(shape=(self.population_size, self.size_of_Q), dtype=int)
       #print(self._parents_indices[0])
        if args.hypercube :
            sampler= qmc.LatinHypercube(d=self.size_of_Q)
            lhs=sampler.random(n=self.population_size)
            for indiv in range (0,self.population_size):
                prob = lhs[indiv]
                copy=[]


                for i in range ( 0,self.size_of_Q):

                    idx=0
                    p=random()

                    while (np.isin(idx,self._parents_indices[indiv]) or p>prob[i]) and idx<self.size_of_Q :
                        idx=idx+1
                        p=random()
                    #print(np.isin(idx,self._parents_indices[indiv]))
                    self._parents_indices[indiv][i]=idx
                    copy.append(idx)
                    #print(copy.count(idx))
            print(self._parents_indices.shape)


        else:

            for j in range(0, self.population_size):
                self._parents_indices[j] = np.arange(self.size_of_Q)
                shuffle(self._parents_indices[j])


        #else:
        #    self.create_childrens()


#+end_example
*** DONE :: Error triggered : Problem solved, due to multiple time the same value in all the individual of the population
#+begin_example
Generation:  0
(40, 32)
Traceback (most recent call last):
  File "/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/src/simulator/simulator.py", line 396, in <module>
    simulator.simulate()
  File "/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/src/simulator/simulator.py", line 340, in simulate
    self.create_childrens()
  File "/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/src/simulator/simulator.py", line 191, in create_childrens
    self.crossover(_mother, _father, i)
  File "/home/djosersimeu/documents/m1_mosig/internship/workspaces/scheduling-simulator/src/simulator/simulator.py", line 171, in crossover
    while _mother[_m] in _son_heritage_father:
IndexError: index 32 is out of bounds for axis 0 with size 32

#+end_example


** TODO Take a look about jupyter notebook which compute the VIF
* Mercredi 21 février
** Implementation of the grid search
+ Creation of jupyter notebook file "GridSearch.ipynb" where we compute the experimental game
*** Random shuffle evaluation

[[file:./images/graph_gs_random_1.png]]
+ The AVGBoundedSlowdown stabilize for all tuples arround the 60th generations
*** Hypercube shuffle evaluation
[[file:./images/graph_gs_hyper.png]]
+ The AVGBounded slowdown stabilize for all tuples arround 300th generations

*** DONE ::Representation in two dimension of the intial distribution of the pop in the two methods
**** Using PCA dimension reduction
#+begin_example
from sklearn.decomposition import PCA

n_compo=2
pca_h =PCA(n_components=n_compo)
lower_dim_data_h =pca_h.fit_transform(init_pop_h)
pca_r =PCA(n_components=n_compo)
lower_dim_data_r =pca_r.fit_transform(init_pop_r)
#+end_example
No real graphical differences
***** Hypercube:
[[file:./images/scatter_h.png]]
***** Random:
[[file:./images/scatter_r.png]]

**** Using the same method as in simulator.py
No real graphical differences
***** Hypercube :
#+begin_example
sampler= qmc.LatinHypercube(d=2)
lhs=sampler.random(n=size_obs)

res_h_x=list()
res_h_y=list()
for i in range(0,size_obs):
    prob=lhs[i]
    copy=[]
    for j in range(0,2):
        idx=randint(0,size_test - 1)
        p=random()

        while (np.isin(idx,copy) or p>prob[j]) :
            idx=randint(0, size_test - 1)
            p=random()
        copy.append(idx)
    res_h_x.append(copy[0])
    res_h_y.append(copy[1])
#+end_example
[[file:./images/sc.png]]
***** Random :
#+begin_example
from random import shuffle,randint,random
from scipy.stats import qmc
import numpy as np
size_obs=40
size_test=32
test1=np.arange(size_test)
shuffle(test1)
res_r_x=list()
res_r_y=list()
for i in range (0,size_obs):
    shuffle(test1)
    res_r_x.append(test1[0])
    res_r_y.append(test1[1])
#+end_example
[[file:./images/sr.png]]
* vendredi 23 février
** DONE :: Graph with 10 time the same tuples in the two configuration with different seed to ensure reproductibility
+ list of seed : 42 , 23 , 32, 15, 234 , 898 , 747, 45, 14, 1
  Changing the value simulator.py line 78 : seed(42) and line 217 : sampler= qmc.LatinHypercube(d=self.size_of_Q,seed=42)
*** For Ramdom shuffle :
[[file:./images/r_shuffle_seed.png]]
*** For Hypercube shuffle :
[[file:./images/h_shuffle_seed.png]]
** DONE :: Learn how to use Grid'5000
+ Tutorial getting started : https://www.grid5000.fr/w/Getting_Started#Connecting_for_the_first_time
+ Usefull ressource for installing nix in Grid'5000 :https://nix-tutorial.gitlabpages.inria.fr/nix-tutorial/installation.html
* Jeudi 29 février
** First utilisation of Grid5000
+ to connect to the server :
  #+begin_example
  ssh grenoble.g5k
  #+end_example
+ to copy a file/folder into my space in the server :
  #+begin_example
  scp myfile.py g5k:targetfolder
  scp -r myfolder g5k:targetfolder
  #+end_example
+ to run a file :
  #+begin_example
  oarsub -l host=1/core=1 "python3 myfile.py"
  #+end_example
+ to see the advancement of my task:
  #+begin_example
  oarstat -u
  #+end_example
** Advancement
+ Sucessely run simple program as hello.python
+ Sucessely copy paste my workspaces into my Grid5000 env
*** Problems
**** DONE :: Problem in the running of simulator.py :
#+begin_example
Traceback (most recent call last):
  File "/home/dsimeu/public/workspaces/scheduling-simulator/src/simulator/simulator.py", line 444, in <module>
    simulator.simulate()
  File "/home/dsimeu/public/workspaces/scheduling-simulator/src/simulator/simulator.py", line 380, in simulate
    self.create_initial_state(tuple_index)
  File "/home/dsimeu/public/workspaces/scheduling-simulator/src/simulator/simulator.py", line 145, in create_initial_state
    subprocess.run(
  File "/usr/lib/python3.9/subprocess.py", line 505, in run
    with Popen(*popenargs, **kwargs) as process:
  File "/usr/lib/python3.9/subprocess.py", line 951, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.9/subprocess.py", line 1823, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/home/dsimeu/public/workspaces/scheduling-simulator/src/simulator/trials_simulator'
#+end_example
+ Advencement the error "No such file or directory" explaination:"libsimgrid.so.3.13 => not found"
#+begin_example
    $ ldd /home/dsimeu/public/workspaces/scheduling-simulator/src/simulator/trials_simulator
	linux-vdso.so.1 (0x00007ffeb05fb000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f3bf10c8000)
	libsimgrid.so.3.13 => not found
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3bf0ef4000)
	/nix/store/z56jcx3j1gfyk4sv7g8iaan0ssbdkhz1-glibc-2.33-56/lib/ld-linux-x86-64.so.2 => /lib64/ld-linux-x86-64.so.2 (0x00007f3bf1225000)
#+end_example
+ Possible usage of guix :https://guix.gnu.org/manual/fr/html_node/
* vendredi 1 mars
** Sucessfuly run simulator.py on Grid5000 method :
+ reserve a specific node:
#+begin_example
dsimeu@fgrenoble:~/public/workspaces$ oarsub -I -l host=1,walltime=1:45 -t deploy
#+end_example
+ deploy the same distrubtuion as me on the node :
  #+begin_example
  dsimeu@fgrenoble:~/public/workspaces$ kadeploy3 ubuntu2204-min
  #+end_example
+ connecting to the node (in our case dahu-30 given by the previous function)
  #+begin_example
  dsimeu@fgrenoble:~/public/workspaces$ ssh root@dahu-30.grenoble.grid5000.fr
  #+end_example
+ install nix on the node :
  #+begin_example
root@dahu-30:~# sh <(curl -L https://nixos.org/nix/install) --daemon
   #+end_example
+ also install packages which allow us to call nix commands:
  #+begin_example
  root@dahu-30:~# apt install nix-bin
  #+end_example
+ return to our grid5000 env by Ctrl+D
+ copy the workspaces folder wich contain our file to the node's environnement:
  #+begin_example
  dsimeu@fgrenoble:~/public$ rsync -r workspaces root@dahu-30.grenoble.grid5000.fr:
  #+end_example
+ run the nix-shell with our file:
  #+begin_example
  root@dahu-30:~/workspaces# nix-shell simgrid.nix
#+end_example
+ run our file:
  #+begin_example
  [nix-shell:~/workspaces/scheduling-simulator/src/simulator]# python3 simulator.py
#+end_example
** Observations:
Not a big improvement compare to the running in local
*** DONE ::
*** DONE :: How to use multiple node with this method
*** TODO :: How to save a particular configuration to setup nodes
* mercredi 6 mars
** Observation
+ The runtime on Grid 5000 is similar to the runtime on my local machine , maybe it's due to the multiple disk acesses at each iteration of the GA
+ Maybe we can decrease the runtime by using parallel programming methods such as OpenMP
+ Grid 5000 allow us to use external hardware devices in our case it usefull for generating the training dataset with 10 000 observation but it will take approximately the same time as a local running.
** Runtime computation
+ 2 Gen/sec
+ We need 100 000 observations
+ Size of Q = 32
+ Nb tuples needed = 3125
+ Nb Gen = 300
+ Runtimes by tuples = 150 sec
+ Global Runtimes = 130 H 13 min
** TODO :: Olivier Richard solution
+ i can decompose the programm set of tuples to use multiple cores by lauching multipler process in dahu
+ To decompose my task i can use gnu parallel (https://www.grid5000.fr/w/GNU_Parallel)
+ 31 process which each execute 100 tuples and 1 process 25 tuples
+ like that the full running will take 4H 11min
+ use tmux
+ attention concurent acces
** DONE :: Comparaison GA Deep search
+ 10 tuples
+ 2*10 curves ( Ga, DS )
+ slodown in function of time
+ time computation : Averge running tim by generation
* Vendredi 8 mars
** Comparaison GA DS
+ The code here https://github.com/fredgrub/scheduling-simulator/blob/main/src/simulator/simulator.py compute the DS algorithm to find a target priorities
+ Run the DS code and store only new minimum for plotting
+ Because of the time needed to run the DS program with 256 000 trials for 10 tuples, for the moment we compute the result only for 1 tuple
*** DONE :: Paralellize the computation of each tuples for the two experimental contexts (DS,GA)
*** DONE :: Do the same thing with a budget of 1 hour for each context and compare them
* Lundi 11 mars
** Paralellize the computation by tuple
*** DONE :: Use the arg for the seed
*** DONE :: Finding a way to parallelize the computation
One node for GA and one node for DS
**** Genetic algo and Deep Search method
+ 10 tuples to compute
+ 10 cpu with 1 tuples
+ First idea : copy 10 time the directory and run simulator.py and simulator_trials.py in each directories with 10 different seed
***** DONE :: See MPI library
* Mercredi 13 mars
** Creation of the parallel context of execution
+ Creation of multiple folder, each one represent a process which will run in parallel of the others
+ Creation of a script for the execution of the processes
  #+begin_example
  #!/bin/bash

# Tableau contenant les chemins des scripts Python à exécuter
scripts=(
    "scheduling-simulator_DS/scheduling-simulator_DS_1/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_2/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_3/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_4/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_5/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_6/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_7/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_8/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_9/src/simulator/simulator_trials.py"
    "scheduling-simulator_DS/scheduling-simulator_DS_10/src/simulator/simulator_trials.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_1/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_2/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_3/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_4/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_5/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_6/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_7/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_8/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_9/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_10/src/simulator/simulator.py"
    # Ajoutez ici les chemins des autres scripts Python que vous souhaitez exécuter
)

# Boucle pour ouvrir 20 terminaux et exécuter les scripts Python
for i in {0..19}
do
    gnome-terminal --command "python3 ${scripts[$i]} ${i}" &
done
#+end_example
** DONE :: Problem, the gnome-terminal instruction is not installed*
** Results of the comparison :
[[file:./images/mean_90_10.png]]
[[file:./images/GAvsDS.png]]
+ As we can see for all the tuple of the evaluation the GA succeed to have a better score than the DS
**
* vendredi 15 mars
** Update of the script:
+ remove the gnome-command by: python3 ${scripts[$i]} ${i} > outputs/output_${i}.txt &
*** DONE :: Z-score
** Writting a script to process the data generation
#+begin_example
#!/bin/bash
sudo-g5k
sh <(curl -L https://nixos.org/nix/install) --daemon --yes
sudo apt install nix-bin -y
#nix-shell simgrid.nix &
# Tableau contenant les chemins des scripts Python à exécuter
scripts=(
    "scheduling-simulator_GA/scheduling-simulator_GA_1/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_2/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_3/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_4/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_5/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_6/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_7/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_8/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_9/src/simulator/simulator.py"
    "scheduling-simulator_GA/scheduling-simulator_GA_10/src/simulator/simulator.py"
    # Ajoutez ici les chemins des autres scripts Python que vous souhaitez exécuter
)

# Boucle pour ouvrir 20 terminaux et exécuter les scripts Python
for i in {0..9}
do
    nix-shell simgrid.nix --command "python3 ${scripts[$i]} ${i} > outputs/output_${i}.txt" &
done

#+end_example
* mercredi 20 mars
** Runnig the generation of the trainning dataset
to generate the training dataset i modified the script previously defined to divide the execution into 32 processes where each one will execute 100 tuples (for each configuration DS an GA)
+ I divided the number of trials in the DS version by 10 to reduce the runtime and because in our observations the DS version find approximatly is minimum in les than 25600 trials in median
+ Now instead of do a deployment we can used the command oarsub -I -l host=1,walltime=1:45
** Beginning of the half report
*** Organization
**** Introduction
**** Preliminary concepts
+ ressources managment in HPC
+ Simgrid
+ scheduling-simulator
+ Genetic Algorithm
+ Grid 5000 ?
+ Multiple linear regressions model
**** Gentic Algorithm deployment
+ finalize the implementation
***** Trying other implementation
+ LatinHypercube
+ Deep search
**** Multiple Linear Regressions model
+ Polynomials of jobs attributes
+ Correlation of jobs attributes
+ Possible solutions
**** Conclusion
*** DONE :: Informations about SimGrid
*** DONE :: Informations about Grid 5000
+ Jusrt a citation : https://www.grid5000.fr/mediawiki/index.php?title=Special:CiteThisPage&page=News&id=102364&wpFormIdentifier=titleform
*** DONE :: Informations about the theorie of the Latin Hypercubes
*** DONE :: Informations about the part of Multiple linear regressions model
* vendredi 22 mars
** DONE :: Collect data from the Grid 5000 front end to save it locally for the GA version
+ Process stop as tuple 82 -83 so for the moment we have 83968 observations of jobs

** TODO :: Prepare the deep search running process in exec_script.sh
** TODO :: Read documentation about the functionnement of the multiple linear regressions before trainning
*** VIF computation
+ read_score_distribution :
  read a csv file which contain the scores, define the cols name to p,q,r and score and call convert_temporal_dataon the dataframe
+ convert_temporal_data:
  divide the temporal informations (p and r) by 3600 (why?
+ compute_vif :
  call the methode variance_inflation_factor for each of the observation of the array (see: https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html)


** TODO :: do sh exec_script.sh i
** scp g5k:grenoble/public/... [destination in local]
* mercredi 27 mars
** Starting writting the half-report
*** Questions
+ Can I introduce scheme in the description of RJMS
* vendredi 29 mars
** starting the second part of the report
+ I must had in the section preliminary concepts : notion of tuples, notions of Average bounded slowdown
* mercredi 3 avril
** TODO :: Look at the exponantial smoothing principle
** observation of the vif jupyter notebook
*** Data:
+ global_training_data_GA.csv: trainning dataset
*** Interpretation
+ a VIF(j) = 1 mean no correlation between the coeff j and the ramaining coefficiebnt of the regression
+ VIFs exceeding 10 are signs of serious multicollinearity requiring correction
+ https://online.stat.psu.edu/stat462/node/180/
*** Observation
**** Linear regression
for all the attributes of jobs, we have a vif value close to 1 so we no correlation between our coef



[[file:images/vif_linear.png]]



**** Quadratic regression
The values of the vif for quadratic regression are greater than the linear ones, the highest values are obtained for q and q² (arround eight)



[[file:images/vif_qdr.png]]



**** Cubic regression
The values of the vif in this context are also hidher than in the previous context, and a majority of them are higher than 10. The highest values are obtained with q , q² and q³.


[[file:images/vif_cub.png]]



**** Other regression
The other regressions parameters follow the same evolution as which one we saw in the previous contexts( higher genral vif and highest values obtain whith polynomials of q )
**** Conclusion
We observed that by increasing the polynomialty of the attributes we also increase the multicolinearity between them, we have a global vif higher than 10 from the cubic regression. We observed also that the highest vif values are always obtained for polynomials of q, by knowing that, maybe we can reduce the multicolinearity by removing the polinomials of q from the regression parameters.
*** Comparaison with the results observed with the GA dataset
We observed that the results are between 0.27 and 0.22 (MSE) we don't have a big influence of the polynomiality of the regression model on the results.
*** Testing of our model
**** TODO :: Understand why we have multiple class of parameters
**** TODO :: Difference between estimate backfilling and runtime?
**** Understanding of the tester folder
***** parameters.c
+ contains the parameters of our multiple linear regressions in different context (default , temporal normalized...)
***** polynomials.c
+ implement the computation of the models in function of a context (PARAMETERS)
***** tester.py
+ Impleme,nt the testing process of our policies on different contexts
+ Save the solwdown of the different policies in different contexts
+ the workload_trace represent the dataset on whch we will test our policie
+ the policies set is the set of ploicies we want to test on our simulation
+ the simulator reprensent the context of sumulation used (estimate backfilling or runtime)
****** TODO :: How can I make the link between the training of the model in regressor and the tester code?
****** TODO :: What are the difference between the differents experimentation contexts?
****** TODO :: add sqare root
* mercredi 10 avril
** Implementation of a grid search to find the polynomiales with the less vif score
+ Maximum vif score of the set is the metric
#+begin_example
def grid_search (dataframe, n):
    best_vif=100000000000000
    best_set=[]
    comb=list(itertools.combinations(possibilites,n))
    for var_set in tqdm(comb, desc="Progression"):
        print
        df_copy = dataframe.copy()

        # Appliquer les transformations pour chaque variable dans l'ensemble
        for var in var_set:
            if var.startswith('sqrt'):
                root_var = var[-2]  # Récupérer la variable ('p', 'q' ou 'r') à partir de la variable sqrt
                df_copy[var] = df_copy[root_var].apply(math.sqrt)
            elif var.startswith(('p', 'q', 'r'))and len(var)==2:
                power = int(var[1:]) if len(var) > 1 else 1  # Récupérer l'exposant du polynôme
                base_var = var[0]  # Récupérer la variable ('p', 'q' ou 'r') à partir de la variable polynomiale
                df_copy[var] = df_copy[base_var] ** power
            elif var in ['p2q', 'q2p', 'p2r', 'r2p', 'q2r', 'r2q']:
                var_1, var_2 = var[0], var[2]  # Récupérer les deux variables ('p', 'q' ou 'r') de la combinaison
                df_copy[var] = (df_copy[var_1] **2) * df_copy[var_2]
            elif var in ['p3q', 'q3p', 'p3r', 'r3p', 'q3r', 'r3q']:
                var_1, var_2 = var[0], var[2]  # Récupérer les trois variables ('p', 'q' ou 'r') de la combinaison
                df_copy[var] = (df_copy[var_1]**3) * df_copy[var_2]
            elif var in ['p4q', 'q4p', 'p4r', 'r4p', 'q4r', 'r4q']:
                var_1, var_2 = var[0], var[2] # Récupérer les quatre variables ('p', 'q' ou 'r') de la combinaison
                df_copy[var] = (df_copy[var_1]**4) * df_copy[var_2]
        res=compute_vif(df_copy)
        max=np.max(res['VIF'])
        if max<best_vif:
            best_vif=max
            best_set=var_set
    print(best_vif)
    print(best_set)

#+end_example
for n fixed as three with 4 as maximal degree the function return:
#+begin_example
1.3632406344945118
('p4q', 'r4p', 'r4q')
#+end_example
for n equal 4 we obtain :
#+begin_example
1.4240461523363361
('r2q', 'p4q', 'p4r', 'r4p')
#+end_example
*** TODO :: Use grid 5000 tu run grid search with high number of cores
** Proof of the pertinence of the use of serialism parameters for the model
+ to implement a proof I used as serialism parameter the mean of the attributes (p,q,r)
*** TODO :: Look at the moment of order 2,3,...
*** Formula
#+begin_example
f(j)=r_mean+(p-p_mean)+(q-q_mean)
#+end_example
* vendredi 12 avril
** Work on the grid search
+ succeed to parralelize the computation of the grid search by size
+ actually running it on grid 5000
+ each process write in a dedicated file the result of the search
** Work on the serialism of the jobs
*** Example
To prove that the mean of the job attributes can be usefull as input of the linear regression we found example where a scheduling policy based on this values give to us good results. I change a bit the formula:
#+begin_example
f(j)=(r_j-r_mean)+(p_j-p_mean)+(q_j-q_mean)
#+end_example
+ in our example the number of cores = 4
+  for the first element scheduled by the method I define that the values of the r_mean _p_mean and q_mean are equal to r_j p_j and q_j, so the priority of the first job will always be 0.
let's take the following example:
#+begin_example
j1 : p=2        q=2     r=0
j2 : p=2        q=3     r=1
j3 : p=3        q=2     r=2
j1 : p=2        q=4     r=3
#+end_example
With these jobs the prioty fonction return :
#+begin_example
f(j1)=0+0+0=0 (1)
f(j2)=1+0+1=2 (2)
f(j3)=1.5+1-0.5=2 (2)
f(j4)=2-0.3+1.7=3.4 (4)
#+end_example
we obtain this scheduling:
#+begin_center
[[file:images/ex1.png]]
#+end_center
Now lets try an other example :
#+begin_example
j1 : p=5        q=4     r=0
j2 : p=2        q=3     r=1
j3 : p=3        q=2     r=2
j1 : p=2        q=2     r=3
#+end_example
we compute the priority:
#+begin_example
f(j1)=0+0+0=0 (4)
f(j2)=1-3-1=-3 (1)
f(j3)=1.5-0.5-1.5=-0.5 (2)
f(j4)=2-1.33-1=-0.33 (3)
#+end_example
we obtained this scheduling :
#+begin_center
[[file:images/ex2.png]]
#+end_center
* mercredi 17 avril
** DONE :: Implementation of a top 5 best vif score for the grid search
#+begin_example
Progression: 100%|██████████████████████████████| 33/33 [00:01<00:00, 19.47it/s]
[1.2727909777191404, 1.2732833543894573, 1.274893096638067, 1.2759070885635, 1.2785223401309322]
[('r4p',), ('r3p',), ('r4q',), ('r3q',), ('r2q',)]
Progression: 100%|████████████████████████████| 435/435 [00:31<00:00, 14.01it/s]
[1.2862065211525044, 1.288677185752982, 1.307909782827608, 1.3200808766937433, 1.322164130430408]
[('r3q', 'r4p'), ('r4p', 'r4q'), ('r3p', 'r4q'), ('r3p', 'r3q'), ('r2q', 'r4p')]
Progression: 100%|██████████████████████████| 5456/5456 [13:55<00:00,  6.53it/s]
[1.3632406344945118, 1.36455181074961, 1.3648916024798887, 1.3665197368900643, 1.3677716761504257]
[('p4q', 'r4p', 'r4q')('p4q', 'r4p', 'r4q')('p4q', 'r4p', 'r4q'), ('r3q', 'p4q', 'r4p'), ('r3p', 'p4q', 'r4q'), ('r3p', 'r3q', 'p4q'), ('r2q', 'p4q', 'r4p')]
#+end_example
** TODO :: Continue the proof about te serialism
#+begin_example

#+end_example
** TODO :: More detail in the abstract descriptif abstract
** TODO :: give name to the axis of the pca graph
** TODO :: replace scrore by- AVGbsld
** TODO :: figurte en PDF
** TODO :: connection sentence in preliminary concepts
** TODO :: Observe the error vif = 1. / (1. - r_squared_i)
* vendredi 19 avril
** Solving the grid search bug
+ We observed that the computation of the polinmoiales is not correct so we mus correct it
+ The polynomiale are already correect it was just that i forget the attributes p , q and r are always computed :
#+begin_example
              p    q          r         p2
0      0.009444    2   4.613333   0.000089
1      0.002222   32   4.627500   0.000005
2      0.049167   16   4.908333   0.002417
3      0.014444    1   4.928889   0.000209
4      2.546944  128   4.931667   6.486926
...         ...  ...        ...        ...
81339  3.888611   32  19.506111  15.121296
81340  0.280833   64  19.533889   0.078867
81341  0.001111    1  83.753056   0.000001
81342  0.018889    2  83.766111   0.000357
81343  0.009444   19  83.814167   0.000089
#+end_example
+ its for that that having p,q,r,p1,q1 and r1 give a high vif values.
** Adding plot at the end of the grid search
I add plot to represent the sumuary of the grid search
#+begin_center
[[file:./images/grid_1.png]]
#+end_center
** Adding the new regression function into the code.
I modify the code of polynomiale.py to see the report of our new regression models.
#+begin_example
def new(x, t0, t1, t2, t3, t4, t5, t6, t7):
    p, q, r = x
    lin_term = lin(x, t0, t1, t2, t3)
    sq_term = (t4*p**4*q + t5*r**4*p + t6*r**4*q)

    return lin_term + sq_term
#+end_example
+ New approach without
#+begin_example
Progression: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5456/5456 [02:35<00:00, 35.06it/s]
[1.0003153515821601, 1.0003947578512513, 1.0004074078936562, 1.0004750801006355, 1.0004796715280073]
[('r4', 'q4p', 'p4r'), ('r4', 'q3p', 'p4r'), ('p4', 'r4', 'q4p'), ('p4', 'q4', 'r4'), ('p4', 'q4p', 'r4p')]
Progression: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [00:06<00:00, 77.01it/s]
[1.0000000687381108, 1.0000003845348913, 1.0000007016175474, 1.0000009714029523, 1.000001195608339]
[('p4', 'r4q'), ('p4', 'r3q'), ('r4', 'p4q'), ('p4q', 'r4q'), ('p4', 'r4')]
#+end_example
*** RESULTS :
#+begin_example
('p4q', 'r4p', 'r4q')="mean_absolute_error": 0.2765630126065031

#+end_example
**
** TODO :: Talk about the ponderation with p and q
** Let's talk
+ Computing regression with attributes with a low vif ensure us of the regularity of the coefficients
+ we obsrevd that our results produce a better mean square error than the qdr cin ... models
+ compare our models on the MSE obtain is not enough we must try them with the tester code
+ for the moment we want to observe the behavior of our models with two and 3 attributes, by testing we can decide to run the grid search for higher number of attributes.
* Mardi 24 mai
** Come back to the internship
I must recheck where i'm to advance in the better condition
 + I have the result of the best combination of attributes of size 3 and 2
+ I can use parrallel programming approach to increase the number of attribute of the gridsearch
+ I have train some fold of attributes
+ I must use them in the tester code
+ I must write the proof about the importance of the jobs serialism in th scheduling
** Tester code
The definition of the polynomiale is made by usin an an array of policies in the code of tester.py and it run the sched-simulator process with as argument the policy used, the policy wanted is find in the code of polynomile.h so it's here where i must add the new polinomiales functions. In addition, the parameters used in the regression model ar define in the code of parameter.h so i must add the parameters computed in the regressor code.
*** First attempt of modification
#+begin_example
double default_new_3_1_parameters[] = {
    0.5068215289329832,
    9.206215685644925e-24,
    6.553326002644232e-15,
    1.6313004708446503e-26
};
#+end_example
*** Important to save parameters
#+begin_example
["CTC-SP2", "SDSC-BLUE", "LUBLIN 256"],
["FCFS", "WFP3", "UNICEF", "SPT", "SAF", "F2", "LIN", "NEW_3_1"],
["ACTUAL", "ESTIMATED"],
#+end_example
*** Successely run  the simulation
In CTC_SP2_ACTUAL_22_1.csv the following slowdown:
#+begin_example
LIN,NEW_3_1
22.622475,100.719362
17.060091,404.450163
106.316168,589.503321
96.078215,164.113145
78.802736,326.308991
357.399834,553.764731
7.7924,269.803833
5.002107,141.812656
3.641912,58.946199
36.289035,546.683427
6.18314,363.690756
13.815736,144.732412
1.798211,23.994623
90.037521,326.517501
156.162032,356.52568
18.894119,710.377754
23.183183,229.515776
69.722574,778.656456
552.452211,315.694662
1046.799808,874.433078
22.336177,241.016212
49.240266,594.078253
#+end_example
[[file:images/New_3_1VSLin.png]]
As we can see the linear regression have a better performance than the new approach (r4,q4p,p4r) in term of AVGBoundedSlowdown
** Comparaison of all the methods
[[file:images/Comparaison_policies.png]]
As we can see by comparing the different regression methods with the new one, our new regression is better than FCFS and WFP3 but the other method are better.
** Work about the proof
*** Objective : prove that the serialsm of the task can be used to improve the performance of our regression model
+ job serialism : the order in which the jobs arrive on the plateform (scheduling j1 before j2 is diffent than scheduling j1 after j2)
+ can be used : implement a memory mechanism as parameter of the model
+ improve the performance of the model: reduce the AVGBoundedSlowdown
*** First Idea : Defining a scheduling policy based on the memory mechanism and show that the AVGBoundedSlowdown with this method is lower than with other methods
+ this approach can show that the serialsm can be take in account to schedule
+ Which memory mechanism? online algorithm? https://www.ime.usp.br/~yw/papers/online/Online-algorithms-albers-survey.pdf
*** Approach choosed
I decide to use the tester code to test a method based on the memeory mecanism such as :
#+begin_example
MEM1:priority = r_mean + (p-p_mean) + (q- q_mean)
MEM2:priority = r_mean + ((p*q) - (p_mean * q_mean)) (area)
#+end_example
the implementation is the following :
#+begin_example
case MEM1:
            if(i==0){
                h_values[i] = submit[i];
            }else{
                h_values[i] = r_mean + (req[i]-p_mean)+(cores[i]-q_mean);
            }
            break;
case MEM2:
            if(i==0){
                h_values[i] = submit[i];
            }else{
                h_values[i] = r_mean + ((req[i]*cores[i])-(p_mean*q_mean));
            }
            break;
#+end_example
**** Results
#+begin_center
[[file:images/Final_Tester_analysis.png]]
#+end_center
As we can see the scheduling policy based on the memory mecanism MEM1 provide a lower average bounded slowdown than the FCFS and WFP3  policies, MEM2 provide the lowest AVGBoundedSlowdown ist really interesting! I must find a way to infer on the utilty of the task serialism.
** Work for the next time
+ In can define a MEM3 based also on the priority previousely given
+ parallelize the computation of the grid search
+ try to construct a grid search also based on the serialism
+ understand how to improve the results of the NEW_3_1 model
+ boxplot seaborn
+ 5 meilleur vif
* Mercredi 15 mai
** Boxplot replace line plot
for better visualization, by adding the 5 combination of pqr with the lowest vif I didn't found a big difference with New_3_1
** Serialism
*** dataset generation
I used the cumulative average to add the mean of p q and r in the dataset:
#+begin_example
import numpy as np
import pandas as pd
df=pd.read_csv('global_training_data_GA.csv',names=['p','q','r','y'])
df = df.iloc[1:].reset_index(drop=True)
print(len(df))
res=pd.DataFrame()
for start in range(0, len(df), 32):
    data = df[start:start+32]
    sorted_data = data.sort_values(by='r', ascending=True)
    shifted_values = sorted_data['p'].shift(1)
    sorted_data['p_mean'] = shifted_values.expanding().mean()
    shifted_values = sorted_data['q'].shift(1)
    sorted_data['q_mean'] = shifted_values.expanding().mean()
    shifted_values = sorted_data['r'].shift(1)
    sorted_data['r_mean'] = shifted_values.expanding().mean()
    sorted_data
    res=pd.concat([res,sorted_data])
res['p_mean'] = res['p_mean'].fillna(res['p'])
res['q_mean'] = res['q_mean'].fillna(res['q'])
res['r_mean'] = res['r_mean'].fillna(res['r'])
res = res.sample(frac=1).reset_index(drop=True)
print(res)
res.to_csv('global_training_data_GA_MEM.csv', index=False)
#+end_example
*** Modification made to compute a regression function with the means
I succeed to train a regression function based on the serialism of the jobs but the result are not good in must check in the trainning dataset have a problem
#+begin_center
[[file:images/Final_Tester_analysis_SER.png]]
#+end_center
By observing the results and the results of the training of the models, i conclude that we have direct link between the MSE and the average bounded slowdown observed in the boxplot.
** Reduce the training MSE
I modified the grid search to save the 10 lowest VIFs
#+begin_example
[('r4', 'q4p', 'p4r'), ('r4', 'q3p', 'p4r'), ('p4', 'r4', 'q4p'), ('p4', 'q4', 'r4'), ('p4', 'q4p', 'r4p'), ('p4', 'r4', 'q3p'), ('p4', 'q3p', 'r4p'), ('r4', 'q2p', 'p4r'), ('p4', 'r3p', 'q4p'), ('r4', 'p3r', 'q4p')]
#+end_example
#+begin_center
[[file:images/10_models_analysis.png]]
#+end_center
As we can see on the graph, the 10 differents model provide us heterogeneous results but stay in average with an higher AVGBoundedSlowdown than the simple Linear regression.
** Approach to explore next tomorrow
to observe the behavior of the MSE, A 3D representation can be helpful:
*** First idea
+ x = The maximum degree of the parameters (Max = 10 , step = 1, start = 1)
+ y = The number of parameters (Max = 10 , step = 1 , start = 2)
+ z = The MSE obtained by the regression
*** Second idea
replace y by the vif score obtained by the function and use only function with 3 parameters (simplify the computation)
* Jeudi 16 mai
** 3D MSE Visualisation
As I discussed last time a 3D representation of the MSE in function of the degree of the parameters and the vif score of the parameters
*** VIF score computation
To select the parameters of the observations of the 3D representation, I modify the code of the grid search previously defined to add a threshold parameter. The grid search the combination of p,q,r which have the best vif score but only if their score is higher than the threshold.
#+begin_example
 if max<best and max>=threshold:
#+end_example
*** Degree of the parameters
I decided to take into account in the representation the average degree (AVGD) of the parameters to understand the impact of the polinomiliaty of the parameters on the MSE obtained. To discretized the AVGD, I defined 4 level of AVGD in function of the observations (1=lowest , ... , 4=highest), we can have somme overlapping between levels be the most important property to satisfy is :
#+begin_example
for all i include in VIF_levels : F(i,1) < F(i,2) < F(i,3) < F(i,4)
#+end_example
Where F (i,j) represent the observation with i as Vif level and j as AVGD level.
*** Implementation
By observing the results of the grid search with a threshold for each VIF level, I selected combinaison of parameter satisfysing the AVGD levels.

| VIF\AVGD | 1                        | 2                 | 3                 | 4                 |
|        1 | p,q,r   (1)              | X                 | r3,q2p,p3r (3.3)  | new_3_5 (>4)      |
|        2 | sqrt(p),pq,qr (1,...)    | q,r2q,q3p (2.6)   | p2q,p3r,p4q (4)   | p4,p4r,r4q (4.6)  |
|        3 | r,pq,p2q (2)             | p2q,r2q,p3q (3.3) | r2q,q3p,q3r (3.6) | q2,q4p,r4p  (4)   |
|        4 | pr,qr,q3r (2.6)          | q2,q2r,q3r (3.3)  | q4,r2q,q3r (3.6)  | r2q,p4r,r4q (4.3) |
|        5 | sqrt(q),q,r2p (1,..)     | p2r,r2q,r4q (3.6) | r2q,r3p,r4q (4)   | r2q,r4p,r4q (4.3) |
|        6 | q,pq,q3p (2.3)           | qr,q2r,p3r (3)    | p2r,p3r,q4p (4)   | X                 |
|        7 | sqrt(p),qr,q2r (1,..)    | q3,pq,p2q (3)     | qr,q2r,q4p (3.3)  | p2r,p3r,p4q (4)   |
|        8 | sqrt(p),p,pr (1,..)      | r2,qr,q2r (2.3)   | r2p,r3p,q3r (3.6) | p3q,p4q,p4r (4.6) |
|        9 | sqrt(r),pq,q2p           | pq,pr,q2p (2.3)   | pq,q2p,q3r (3)    | p3q,p4q,r4q (4.6) |
|       10 | sqrt(p),sqrt(r),p (0,..) | q,pq,p2q (2)      | qr,p3q,p4q (3.6)  | q2r,p3q,p4q (4)   |

In parenthesis the approximate AVGD of the model.
Aftet definning the parameters of the regression functions to test, i modified the code of regressor.py and polinomials.py to perform the training of my functions:
Polynomial.py :
#+begin_example
######### VIF ~ 1 ###########

def vif_1_deg_1(x, t0, t1, t2,t3):
    p, q, r = x
    lin_term = (t0 + t1*p + t2*q +t3*r)
    return lin_term

def vif_1_deg_3(x, t0, t1, t2,t3):
    p, q, r = x
    lin_term = (t0 + t1*(r**3) + t2*(q**2)*p +t3*(p**3)*r)
    return lin_term

def vif_1_deg_4(x, t0, t1, t2,t3):
    p, q, r = x
    lin_term = (t0 + t1*(p**4) + t2*(q**4)*p +t3*(r**4)*p)
    return lin_term
#+end_example
Regressor.py:
#+begin_example
if __name__ == "__main__":

    funct=[[vif_1_deg_1,vif_1_deg_3,vif_1_deg_4],
           [vif_2_deg_1,vif_2_deg_2,vif_2_deg_3,vif_2_deg_4],
           [vif_3_deg_1,vif_3_deg_2,vif_3_deg_3,vif_3_deg_4],
           [vif_4_deg_1,vif_4_deg_2,vif_4_deg_3,vif_4_deg_4],
           [vif_5_deg_1,vif_5_deg_2,vif_5_deg_3,vif_5_deg_4],
           [vif_6_deg_1,vif_6_deg_2,vif_6_deg_3],
           [vif_7_deg_1,vif_7_deg_2,vif_7_deg_3,vif_7_deg_4],
           [vif_8_deg_1,vif_8_deg_2,vif_8_deg_3,vif_8_deg_4],
           [vif_9_deg_1,vif_9_deg_2,vif_9_deg_3,vif_9_deg_4],
           [vif_10_deg_1,vif_10_deg_2,vif_10_deg_3,vif_10_deg_4]]

    for i in range (0,10):
        print(f"Performing the regression {i+1}")
        regressor = Regressor(SCORE_DISTRIBUTION, SCORE_DISTRIBUTION_MEM, funct[i])
        report = f"vif_{i+1}_report.json"
        regressor.regression(report)
        print("Done!")
        print("Regression report saved to '{}'".format(report))
#+end_example
** Results
#+begin_center
[[file:images/3D_MSE_4_10_0_0.png]]
[[file:images/3D_MSE_4_10_0_90.png]]

#+end_center
As we can see on the resuting 3D graph, the plane contruct by the described method, is not perfectly smooth, it can be due to the differences in the informations provide by the parameters of each function. But this representation is enough representative provide to us a deeper understanding of the impact of the AVGD and the VIF on the MSE :
+ the plane is not horizontal, on the AVGD axis, it means tht by increasing the AVGD we also increase the MSE obtained
+ the plane is also not totally horizontal on the VIF axis, we can see that the MSE increase for a If value between 1 and an 4, but after 4 the MSE slope decrese for the observationwith a low AVGD. We can imagine that with higher value for the vif threshold the MSE will continue to decrease.
* Vendredi 17 main
** Second 3D analysis
To validate the behavior of the MSE seen in the first 3D representation, I extend the exprerimental analysis by trying with 4 parameter instead of 3. To minimize the computational complexity of the comparison of VIF score for 4 parameters, i used random.sample python function to bound the number of trial to compute to 5000.
** Implementation

| VIF\AVGD | 1                                            | 2                                       | 3                                       | 4                                       |
|        1 | X                                            | ('sqrt(r)', 'p2', 'q4', 'r4') (2,...)   | ('sqrt(p)', 'p3', 'q4', 'r4p') (3,..)   | ('sqrt(r)', 'q4', 'p4q', 'r4p') (3,...) |
|        2 | ('sqrt(q)', 'p2', 'p1q', 'q1r') (1,..)       | ('q1', 'r1', 'r2q', 'q4p') (2,5)        | ('q1', 'q2r', 'p3q', 'q4p') (3,..)      | ('r4', 'r3q', 'p4q', 'q4r')(>4)         |
|        3 | ('sqrt(p)', 'sqrt(r)', 'q1r', 'r2q') (1,...) | ('sqrt(p)', 'q3', 'r3', 'p1q') (2,..)   | ('q2', 'p1q', 'p2r', 'r4p') (3)         | ('q2', 'p2r', 'r3p', 'q4p')  (>3)       |
|        4 | X                                            | ('q1', 'p1q', 'p3q', 'q4r') (2,5)       | ('q1', 'q1r', 'q4p', 'q4r') (3,..)      | ('r2', 'r4', 'r4p', 'q4r') (4)          |
|        5 | ('sqrt(p)', 'q1', 'q3', 'q1r') (1,..)        | ('sqrt(q)', 'q1', 'p3', 'p3r') (2,..)   | ('p1q', 'p1r', 'q3p', 'r3p') (3)        | ('q3', 'p2q', 'r3p', 'q4p')(>3)         |
|        6 | ('sqrt(r)', 'p1', 'r1', 'q3') (1,..)         | ('sqrt(q)', 'p1', 'r2q', 'r4q') (2,..)  | ('sqrt(q)', 'r2q', 'p4r', 'r4q') (3,..) | X                                       |
|        7 | ('sqrt(p)', 'sqrt(r)', 'r1', 'q4') (1.5)     | ('sqrt(p)', 'q1r', 'p2q', 'q2r') (2,..) | ('q1', 'q2', 'q3r', 'p4r') (3)          | ('r2', 'p2r', 'p3r', 'r4q') (>3)        |
|        8 | ('sqrt(p)', 'p1', 'q1r', 'q2r') (1,..)       | ('sqrt(r)', 'p2', 'p3', 'r2p') (2,..)   | ('p2', 'p3', 'p2r', 'p3q') (3)          | ('r2q', 'r3p', 'q4r', 'r4q') (>4)       |
|        9 | ('sqrt(q)', 'q1', 'p4', 'p1q') (1,..)        | ('sqrt(p)', 'q3', 'p1q', 'q3p') (2,..)  | ('q3', 'r3', 'p2q', 'q2p')(3)           | ('r2p', 'r2q', 'q4r', 'r4q') (4)        |
|       10 | ('sqrt(p)', 'sqrt(r)', 'p1', 'p3q') (1,..)   | ('q1', 'q2', 'p1r', 'q2p') (2)          | ('q3', 'p4', 'p2q', 'q2p') (3,..)       | ('p3q', 'p4q', 'q4r', 'r4q') (>4)       |
** Results
#+begin_center
[[file:images/3D_MSE_s4_20_40.png]]
[[file:images/3D_MSE_s4_0_0.png]]
[[file:images/3D_MSE_s4_0_90.png]]
#+end_center
The 3D representation is very similar to the previous representation with three parameters. I also find that 7_1 have the lowest MSE so we tried it with the tester.
#+begin_center
[[file:images/LIN_VS_S4_V7_D1.png]]
#+end_center
As we can see the linear regression is always better than the best regression we found in the previous step in a testing context
** About our train-test assumption
about the training :
#+begin_example
MSE(LIN)=0.21669054758575446
MSE(S4_V7_D1)=0.20868988347079592
MSE(LIN)>MSE(S4_V7_D1)
#+end_example
but in the testing process:
#+begin_example
for all testing context : AVGBoundedSlowdown(LIN)<AVGBoundedSlowdown(S4_V7_D1)
#+end_example
By this fact we can't continue to take the train-test assumpution (lowest MSE ~ lowest AVGBoundedSlowdown)
*** Some way to explain this phenomenon
+ trainning dataset unrealistic
+ overfitting of the S4_V7_D1 model
** For next time
+ Try with other regression with a high MSE to see the behavior of the previous phenomenom
+ ask Danilo for that
* Lundi 20 mai
** Understand the reason of the non-correlation between the MAE and the AVGBoundedSlowdown
I must highlight this non correlation by using statistical correlation metrics.
*** Pearson test
The Pearson coef is a metrics weich represent the linear relation between two continious varibles.
+ X1 = MAE of all the each attibutes combination
+ X2 = mean of the AVGBoundedSlowdown of all experiment contexts for each attibutes combination
+ H0 = Independence of X1 and X2
**** Interpretation
#+begin_example
from scipy.stats import pearsonr
pd.DataFrame(pearsonr(X1,X2),index = ['pearson_coeff','p_value'],columns = ['test_result'])
#+end_example
#+begin_example
if p_value < 0.05 : dependance (reject H0)
if pearson_coeff ~ 1 : X1 and X2 are positively corrolated
if pearson_coeff ~ 0 : X1 and X2 are non corrolated
if pearson_coeff ~ -1 : X1 and X2 are negatively corrolated
#+end_example
**** Implementation
***** TODO :: Select the attributes combinations to evaluate
10 randomly selected from the attributes combinations used in the 3D representation
#+begin_example
for attrbutes combinations of size 3 = LIN , S3_V1_D3 , S3_V2_D1, S3_V10_D1, S3_V10_D4
for attrbutes combinations of size 4 = S4_V7_D1, S4_V4_D3, S4_V9_D2, S4_V3_D1, S4_V9_D4
#+end_example
***** TODO :: Performing the Pearson test
**** Citation
#+begin_example
@article{plackett1983karl,
  title={Karl Pearson and the chi-squared test},
  author={Plackett, Robin L},
  journal={International statistical review/revue internationale de statistique},
  pages={59--72},
  year={1983},
  publisher={JSTOR}
}
#+end_example
**** Results
***** MAE
#+begin_example
[0.21717980982772267,
 0.2409854268393933,
 0.21693984120016557,
 0.21089234508925758,
 0.243989158857399,
 0.20902869180559244,
 0.23105163006866702,
 0.21469804751448088,
 0.21222638918450404,
 0.24586482431455228]
#+end_example
***** AVGBoundedSlowdown
#+begin_center
[[file:images/Corr_analysis_SER.png]]
#+end_center

Average Bounded slowdown for all the experimental context :
#+begin_example
LIN          1164.351312
S3_V1_D3     1786.410008
S3_V2_D1      257.833541
S3_V10_D1    4468.807476
S3_V10_D4     542.374548
S4_V7_D1      411.896122
S4_V4_D3     1888.208262
S4_V9_D2      920.520924
S4_V3_D1     2285.110092
S4_V9_D4      362.901237
#+end_example
***** Pearson test results
#+begin_center
[[file:images/pearson_coeff.png]]
#+end_center
***** Analysis
As we can see the p-value of the pearson test is higher than 0.05 so i can conclude that the MAE provide after the training is independent to the AVGBSLD provide by the tester.
